{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49e342dc-50d5-42d8-8338-c04d6f3e093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import typing as tp\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class MockResponse:\n",
    "    headers: dict\n",
    "    def raise_for_status(self): pass\n",
    "\n",
    "class NCEIBackendMock:\n",
    "    def __init__(self):\n",
    "        # Simulamos que tenemos un archivo de 50MB\n",
    "        self.file_size = 50 * 1024 * 1024  \n",
    "        self.chunk_count = 50 # Lo dividiremos en 50 partes de 1MB\n",
    "\n",
    "    def size(self, *, uri: str) -> int:\n",
    "        return self.file_size\n",
    "\n",
    "    def read_(self, *, uri: str, chunk_size: int = 1024 * 1024) -> tp.Iterable[bytes]:\n",
    "        print(f\"\\n[Mock] Iniciando stream para: {uri}\")\n",
    "        for _ in range(self.chunk_count):\n",
    "            time.sleep(0.1)  # Simulamos latencia de red\n",
    "            yield b\"0\" * chunk_size # Enviamos un MB de \"datos\" dummy\n",
    "\n",
    "# Mock simple del Datasource para que funcione con smart_download\n",
    "class DatasourceMock:\n",
    "    def __init__(self):\n",
    "        self.backend = NCEIBackendMock()\n",
    "        self.mountpoint = \"/ncei_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61558fc1-340c-496c-aabc-29a85e4b4a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib as pl\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def smart_download(ds, remote_uris: list[str], local_dest: str | pl.Path, max_workers: int = 4):\n",
    "    \"\"\"\n",
    "    Descarga archivos usando streaming y progreso por bytes si está disponible,\n",
    "    o progreso por archivos como fallback.\n",
    "    \"\"\"\n",
    "    local_root = pl.Path(local_dest)\n",
    "    \n",
    "    def _download_one(uri: str, position: int):\n",
    "        # 1. Intentar obtener el tamaño para la barra de progreso\n",
    "        try:\n",
    "            total_size = ds.backend.size(uri=uri)\n",
    "        except (AttributeError, Exception):\n",
    "            total_size = None\n",
    "\n",
    "        # 2. Preparar ruta local\n",
    "        # (Uso de lstrip para asegurar que sea relativa al root local)\n",
    "        relative_path = uri.split(ds.mountpoint)[-1].lstrip(\"/\") \n",
    "        target_path = local_root / relative_path\n",
    "        target_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # 3. Descarga con streaming si read_ existe\n",
    "        if hasattr(ds.backend, 'read_') and total_size:\n",
    "            with tqdm(\n",
    "                total=total_size, \n",
    "                unit='B', \n",
    "                unit_scale=True, \n",
    "                desc=uri.split('/')[-1],\n",
    "                leave=False, # La barra desaparece al terminar para no saturar\n",
    "                position=position # Evita que las barras se solapen en multihilo\n",
    "            ) as pbar:\n",
    "                with open(target_path, \"wb\") as f:\n",
    "                    for chunk in ds.backend.read_(uri=uri):\n",
    "                        f.write(chunk)\n",
    "                        pbar.update(len(chunk))\n",
    "        else:\n",
    "            # Fallback al método tradicional si no hay streaming disponible\n",
    "            content = ds.load(uri=uri) # Asumiendo que load usa backend.read()\n",
    "            target_path.write_bytes(content.getvalue())\n",
    "\n",
    "    # Ejecución\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Asignamos una posición a cada hilo para que las barras de tqdm se apilen\n",
    "        futures = [\n",
    "            executor.submit(_download_one, uri, i % max_workers) \n",
    "            for i, uri in enumerate(remote_uris)\n",
    "        ]\n",
    "        \n",
    "        # Barra de progreso global (por archivos)\n",
    "        with tqdm(total=len(remote_uris), desc=\"Progreso Global\", unit=\"file\") as main_pbar:\n",
    "            for future in as_completed(futures):\n",
    "                main_pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e089c6f5-9614-439f-a1e5-3b22714a066d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando prueba de descarga concurrente con streaming...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a60f1ffbe245f08b85b8d9aa53dfff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sensor_v1_2024.nc:   0%|          | 0.00/52.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac757d172a2c41ef82f7932815d30683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "metadata_global.nc:   0%|          | 0.00/52.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59d9b0ee0c4e446ca205cd6301bb10dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sensor_v2_2024.nc:   0%|          | 0.00/52.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00fe317cc4c54ceab4669f0053c2ceca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progreso Global:   0%|          | 0/3 [00:00<?, ?file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Mock] Iniciando stream para: /ncei_data/sensor_v2_2024.nc\n",
      "\n",
      "[Mock] Iniciando stream para: /ncei_data/sensor_v1_2024.nc\n",
      "\n",
      "[Mock] Iniciando stream para: /ncei_data/metadata_global.nc\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pathlib as pl\n",
    "\n",
    "# 1. Instanciar el mock\n",
    "ds_mock = DatasourceMock()\n",
    "\n",
    "# 2. Definir archivos ficticios para descargar\n",
    "archivos_ficticios = [\n",
    "    \"/ncei_data/sensor_v1_2024.nc\",\n",
    "    \"/ncei_data/sensor_v2_2024.nc\",\n",
    "    \"/ncei_data/metadata_global.nc\"\n",
    "]\n",
    "\n",
    "# 3. Ejecutar la descarga inteligente\n",
    "print(\"Iniciando prueba de descarga concurrente con streaming...\")\n",
    "smart_download(\n",
    "    ds=ds_mock, \n",
    "    remote_uris=archivos_ficticios, \n",
    "    local_dest=\"./test_mock_download\",\n",
    "    max_workers=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf2e72c-8ed6-433c-babc-26e5c432fe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tfg.storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de35138-0249-455e-9276-fd27e88b6b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = tfg.storage.use_gcs_cloud(bucket=\"gcp-public-data-goes-16\", cache_file=\"hola.json\", expire_after=100.0)\n",
    "ls = tfg.storage.use_local_drive(root_path=\".\")\n",
    "\n",
    "content = gc.list(prefix=\"/ABI-L2-CMIPF/2020/319/20\")\n",
    "data = gc.load(uri=content[0])\n",
    "\n",
    "ls.save(uri=content[0], data=data)\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736798d7-66c2-4d02-a51b-8ed01e2ee777",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tfg.storage.use_aws_cloud(bucket=\"noaa-goes16\", cache_file=\"hola.json\", expire_after=100.0)\n",
    "\n",
    "content = ds.list(prefix=\"/ABI-L2-CMIPF/2020/319/20\")\n",
    "data = ds.load(uri=content[1])\n",
    "\n",
    "ls.save(uri=content[1], data=data)\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9016d8fb-a2cb-4603-aec6-19d6f9121ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = tfg.storage.use_local_drive(root_path=\".\")\n",
    "content = ls.list(prefix=\"/ABI-L2-CMIPF/2020/319/20\")\n",
    "data = ls.load(uri=content[0])\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c49ebb-ad93-4aab-9c75-4192d8b11807",
   "metadata": {},
   "outputs": [],
   "source": [
    "gd = tfg.storage.use_google_drive()\n",
    "gd.save(uri=content[0], data=data)\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482f52b8-8ed0-4de7-87b8-bc7d69f90355",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = tfg.storage.use_ncei_archive(base_url=\"https://www.ncei.noaa.gov/data/gridsat-goes/access/goes\", cache_file=\"hola.json\", expire_after=100.0)\n",
    "ls = tfg.storage.use_local_drive(root_path=\".\")\n",
    "\n",
    "content = nc.list(prefix=\"/2007/08/\")\n",
    "data = nc.load(uri=content[0])\n",
    "\n",
    "ls.save(uri=content[0], data=data)\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d10469-3a36-4481-aa6b-31a021290d97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
