{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49e342dc-50d5-42d8-8338-c04d6f3e093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import typing as tp\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class MockResponse:\n",
    "    headers: dict\n",
    "    def raise_for_status(self): pass\n",
    "\n",
    "class MockMapper:\n",
    "\n",
    "    def to_native(self, uri: str) -> str:\n",
    "        return uri\n",
    "\n",
    "class NCEIBackendMock:\n",
    "    def __init__(self):\n",
    "        # Simulamos que tenemos un archivo de 50MB\n",
    "        self.file_size = 50 * 1024 * 1024\n",
    "        self.chunk_count = 50 # Lo dividiremos en 50 partes de 1MB\n",
    "\n",
    "    def size(self, *, uri: str) -> int:\n",
    "        return self.file_size\n",
    "\n",
    "    def read_chunk(self, *, uri: str, chunk_size: int = 1024 * 1024) -> tp.Iterable[bytes]:\n",
    "        print(f\"\\n[Mock] Iniciando stream para: {uri}\")\n",
    "        for _ in range(self.chunk_count):\n",
    "            latencia = random.uniform(0.01, 0.15)\n",
    "            time.sleep(latencia)  # Simulamos latencia de red\n",
    "            yield b\"0\" * chunk_size # Enviamos un MB de \"datos\" dummy\n",
    "\n",
    "# Mock simple del Datasource para que funcione con smart_download\n",
    "class DatasourceMock:\n",
    "    def __init__(self):\n",
    "        self.backend = NCEIBackendMock()\n",
    "        self.mapper = MockMapper()\n",
    "        self.mountpoint = \"/ncei_data\"\n",
    "\n",
    "    def get_size(self, uri: str) -> int:\n",
    "        return self.backend.size(uri=uri)\n",
    "\n",
    "    def stream(self, uri: str) -> tp.Iterable[bytes]:\n",
    "        return self.backend.read_chunk(uri=uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61558fc1-340c-496c-aabc-29a85e4b4a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib as pl\n",
    "from tqdm.auto import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "def smart_download(ds, remote_uris: list[str], local_dest: str | pl.Path, max_workers: int = 4):\n",
    "    \"\"\"\n",
    "    Descarga archivos usando streaming.\n",
    "    \"\"\"\n",
    "    local_root = pl.Path(local_dest)\n",
    "\n",
    "    # Ejecución\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Barra de progreso global (por archivos)\n",
    "        with tqdm(total=len(remote_uris), desc=\"Progreso Global\", unit=\"file\", position=0, leave=True) as main_pbar:\n",
    "            # Asignamos una posición a cada hilo para que las barras de tqdm se apilen\n",
    "            futures = [\n",
    "                executor.submit(_download_one, ds, local_root, uri, i % max_workers + 1)\n",
    "                for i, uri in enumerate(remote_uris)\n",
    "            ]\n",
    "            for future in as_completed(futures):\n",
    "                main_pbar.update(1)\n",
    "\n",
    "def _download_one(ds, local_root, uri: str, position: int):\n",
    "    # 1. Intentar obtener el tamaño para la barra de progreso\n",
    "    total_size = ds.get_size(uri=uri)\n",
    "\n",
    "    # 2. Preparar ruta local\n",
    "    # (Uso de lstrip para asegurar que sea relativa al root local)\n",
    "    relative_path = uri.split(ds.mountpoint)[-1].lstrip(\"/\")\n",
    "    target_path = local_root / relative_path\n",
    "    target_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 3. Descarga con streaming\n",
    "    with tqdm(\n",
    "        total=total_size,\n",
    "        unit='B',\n",
    "        unit_scale=True,\n",
    "        desc=uri.split('/')[-1],\n",
    "        leave=False, # La barra desaparece al terminar para no saturar\n",
    "        position=position # Evita que las barras se solapen en multihilo\n",
    "    ) as pbar:\n",
    "        with open(target_path, \"wb\") as f:\n",
    "            for chunk in ds.stream(uri=uri):\n",
    "                f.write(chunk)\n",
    "                pbar.update(len(chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e089c6f5-9614-439f-a1e5-3b22714a066d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando prueba de descarga concurrente con streaming...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c55f03a5ef9947559fd16be679a7fa62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progreso Global:   0%|          | 0/6 [00:00<?, ?file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45980595245143e7b8ed10354a78082a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sensor_v1_2024.nc:   0%|          | 0.00/52.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Mock] Iniciando stream para: /ncei_data/sensor_v1_2024.nc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f39868a989c34d0eb5fb1c988efe18c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sensor_v3_2024.nc:   0%|          | 0.00/52.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a6bbb866d014ab8b2c9bd3a51ea017e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sensor_v2_2024.nc:   0%|          | 0.00/52.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Mock] Iniciando stream para: /ncei_data/sensor_v3_2024.nc\n",
      "\n",
      "[Mock] Iniciando stream para: /ncei_data/sensor_v2_2024.nc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "937547b9c8df4aea932a80eb61799770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sensor_v4_2024.nc:   0%|          | 0.00/52.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Mock] Iniciando stream para: /ncei_data/sensor_v4_2024.nc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbfeb007b2964bf78e78f1e0dce7cfa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sensor_v5_2024.nc:   0%|          | 0.00/52.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Mock] Iniciando stream para: /ncei_data/sensor_v5_2024.nc\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d3c34def7b40d1af8fb5634d731a13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "metadata_global.nc:   0%|          | 0.00/52.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Mock] Iniciando stream para: /ncei_data/metadata_global.nc\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pathlib as pl\n",
    "\n",
    "# 1. Instanciar el mock\n",
    "ds_mock = DatasourceMock()\n",
    "\n",
    "# 2. Definir archivos ficticios para descargar\n",
    "archivos_ficticios = [\n",
    "    \"/ncei_data/sensor_v1_2024.nc\",\n",
    "    \"/ncei_data/sensor_v2_2024.nc\",\n",
    "    \"/ncei_data/sensor_v3_2024.nc\",\n",
    "    \"/ncei_data/sensor_v4_2024.nc\",\n",
    "    \"/ncei_data/sensor_v5_2024.nc\",\n",
    "    \"/ncei_data/metadata_global.nc\",\n",
    "]\n",
    "\n",
    "# 3. Ejecutar la descarga inteligente\n",
    "print(\"Iniciando prueba de descarga concurrente con streaming...\")\n",
    "smart_download(\n",
    "    ds=ds_mock,\n",
    "    remote_uris=archivos_ficticios,\n",
    "    local_dest=\"./test_mock_download\",\n",
    "    max_workers=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cf2e72c-8ed6-433c-babc-26e5c432fe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tfg.storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0de35138-0249-455e-9276-fd27e88b6b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = tfg.storage.use_gcs_cloud(bucket=\"gcp-public-data-goes-16\", cache_file=\"hola.json\", expire_after=100.0)\n",
    "ls = tfg.storage.use_local_drive(root_path=\".\")\n",
    "\n",
    "content = gc.list(prefix=\"/ABI-L2-CMIPF/2020/319/20\")\n",
    "# data = gc.load(uri=content[0])\n",
    "\n",
    "# ls.save(uri=content[0], data=data)\n",
    "# print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736798d7-66c2-4d02-a51b-8ed01e2ee777",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tfg.storage.use_aws_cloud(bucket=\"noaa-goes16\", cache_file=\"hola.json\", expire_after=100.0)\n",
    "\n",
    "content = ds.list(prefix=\"/ABI-L2-CMIPF/2020/319/20\")\n",
    "data = ds.load(uri=content[1])\n",
    "\n",
    "ls.save(uri=content[1], data=data)\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9016d8fb-a2cb-4603-aec6-19d6f9121ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = tfg.storage.use_local_drive(root_path=\".\")\n",
    "content = ls.list(prefix=\"/ABI-L2-CMIPF/2020/319/20\")\n",
    "data = ls.load(uri=content[0])\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c49ebb-ad93-4aab-9c75-4192d8b11807",
   "metadata": {},
   "outputs": [],
   "source": [
    "gd = tfg.storage.use_google_drive()\n",
    "gd.save(uri=content[0], data=data)\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482f52b8-8ed0-4de7-87b8-bc7d69f90355",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = tfg.storage.use_ncei_archive(base_url=\"https://www.ncei.noaa.gov/data/gridsat-goes/access/goes\", cache_file=\"hola.json\", expire_after=100.0)\n",
    "ls = tfg.storage.use_local_drive(root_path=\".\")\n",
    "\n",
    "content = nc.list(prefix=\"/2007/08/\")\n",
    "data = nc.load(uri=content[0])\n",
    "\n",
    "ls.save(uri=content[0], data=data)\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93d10469-3a36-4481-aa6b-31a021290d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSatProductLocatorGC(name='GOES', origins=['goes12'], versions=['v01'], file_date_format='%Y.%m.%d.%H%M', file_date_pattern='\\\\d{4}\\\\.\\\\d{2}\\\\.\\\\d{2}\\\\.\\\\d{4}', file_prefix='GridSat', path_date_format='%Y/%m', path_prefix='goes/')\n",
      "('https://www.ncei.noaa.gov/data/gridsat-goes/access/',)\n",
      "Help on GridSatProductLocatorGC in module goesdl.gridsat.locator_gc object:\n",
      "\n",
      "class GridSatProductLocatorGC(goesdl.gridsat.locator.GridSatProductLocator)\n",
      " |  GridSatProductLocatorGC(\n",
      " |      scene: str,\n",
      " |      origins: str | list[str],\n",
      " |      versions: str | list[str] = 'v01'\n",
      " |  ) -> None\n",
      " |\n",
      " |  Represent the GridSat-GOES/CONUS imagery dataset product locator.\n",
      " |\n",
      " |  This class implements the `GridSatProductLocator` abstract class\n",
      " |  for the GridSat-GOES/CONUS (Geostationary Operational Environmental\n",
      " |  Satellites - GOES/CONUS) dataset product locator.\n",
      " |\n",
      " |  Instances of this class are responsible for generating a list of\n",
      " |  folder paths based on the dataset's directory structure and naming\n",
      " |  conventions, product details, and a specified date range. The\n",
      " |  generated paths cover each year within the date range. Paths to the\n",
      " |  folders containing the initial and final dates are included in the\n",
      " |  list.\n",
      " |\n",
      " |  Instances of this class are also responsible for verifying if a\n",
      " |  given filename matches the product filename pattern based on the\n",
      " |  dataset's naming conventions and product specifications, and for\n",
      " |  extracting the corresponding `datetime` information from the\n",
      " |  product's filename.\n",
      " |\n",
      " |  The data in the GridSat-GOES/CONUS dataset products comes from GOES\n",
      " |  second generation (GOES-I to GOES-M) series, GOES-8 to GOES-15. The\n",
      " |  dataset provides data for two separate scenes: the entire GOES\n",
      " |  domain (Full Disk) and the CONUS domain (Contiguous United States).\n",
      " |  The scene and origin names are reflected in the product's path and\n",
      " |  filename, as does the product's version. The product's filename\n",
      " |  pattern is as follows:\n",
      " |\n",
      " |  'GridSat-<SCENE>.<origin>.<yyyy>.<mm>.<dd>.<HH><MM>.<version>.nc',\n",
      " |\n",
      " |  where `<SCENE>` is the scene name in uppercase (e.g. 'CONUS' or\n",
      " |  'GOES'); `<origin>` is the satellite identifier in lowercase (e.g.\n",
      " |  'goes08' to 'goes15'); `<yyyy>` is the gregorian year number;\n",
      " |  `<mm>`, `<dd>`, `<HH>` and <MM> are the month, day, hour and minute,\n",
      " |  respectively, using two digits padded with zeros; and `<version>` is\n",
      " |  the product's version(e.g. 'v01').\n",
      " |\n",
      " |  The dataset's files are hosted on the servers of the NOAA's National\n",
      " |  Centers for Environmental Information (NCEI), the product's file\n",
      " |  path pattern is as follows:\n",
      " |\n",
      " |  'https://<net-location>/data/gridsat-goes/access/<scene>/<yyyy>/<mm>/',\n",
      " |\n",
      " |  where `<net-location>` is 'www.ncei.noaa.gov', and `<scene>` is the\n",
      " |  scene name in lowercase (e.g. 'conus' or 'goes'). `<yyyy>` and\n",
      " |  `<mm>` are, respectively, the gregorian year number and the month\n",
      " |  number using two digits padded with zeros.\n",
      " |\n",
      " |  Input is half-hourly data from the GOES second generation satellite\n",
      " |  series with gridded 0.04°x0.04° spatial resolution that spans from\n",
      " |  1994 to 2017. Six total channels are available\n",
      " |\n",
      " |  For more information visit the following link and links therein:\n",
      " |  https://www.ncei.noaa.gov/products/satellite/gridded-goes-conus\n",
      " |\n",
      " |  Notes\n",
      " |  -----\n",
      " |  No datasource is supported yet.\n",
      " |\n",
      " |  Methods\n",
      " |  -------\n",
      " |  get_base_url(datasource: str) -> str:\n",
      " |      Get the base URL for the GridSat-GOES/CONUS imagery dataset's\n",
      " |      products.\n",
      " |  next_time(current_time: datetime) -> datetime\n",
      " |      Get the next time interval. GridSat-GOES/CONUS dataset organises\n",
      " |      the data by month.\n",
      " |  normalise_times(datetime_ini: datetime, datetime_fin: datetime)\n",
      " |      -> tuple[datetime, datetime]\n",
      " |      Normalise the initial and final datetimes.\n",
      " |  truncate_to_month(time: datetime) -> datetime\n",
      " |      Truncate the `datetime` to the current month.\n",
      " |\n",
      " |  Caution\n",
      " |  -------\n",
      " |  Members of this class not defined by the `ProductLocator` interface\n",
      " |  are helper methods and can be considered as implementation details,\n",
      " |  even though they are defined as part of the public API. In future\n",
      " |  releases, these methods may be moved to a private scope, suffer\n",
      " |  name changes, or be removed altogether.\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      GridSatProductLocatorGC\n",
      " |      goesdl.gridsat.locator.GridSatProductLocator\n",
      " |      goesdl.dataset.locator_gg.ProductLocatorGG\n",
      " |      goesdl.dataset.locator.ProductLocator\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __init__(\n",
      " |      self,\n",
      " |      scene: str,\n",
      " |      origins: str | list[str],\n",
      " |      versions: str | list[str] = 'v01'\n",
      " |  ) -> None\n",
      " |      Initialise a GridSat-GOES/CONUS imagery dataset product locator.\n",
      " |\n",
      " |      Constructs a GridSat-GOES/CONUS imagery dataset product locator\n",
      " |      object.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      scene : str\n",
      " |          The scene ID for the dataset. Supported scenes are \"F\" (Full\n",
      " |          Disk) and \"C\" (CONUS, Contiguous United States). Due to how\n",
      " |          the GridSat-GOES/CONUS dataset directories are organised,\n",
      " |          only a single scene may be provided.\n",
      " |      origins : str | list[str]\n",
      " |          The origin of the GridSat-GOES/CONUS imagery dataset\n",
      " |          product, namely a satellite identifier, e.g. \"G08\".\n",
      " |          The origin may be a single origin or a list of origins.\n",
      " |      versions : str | list[str]\n",
      " |          The version of the GridSat-GOES/CONUS imagery dataset\n",
      " |          product; e.g., \"v01\". The version may be a single version\n",
      " |          or a list of versions. Only the latest version is available\n",
      " |          in the public repository. The default is the latest version\n",
      " |          (\"v01\").\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          If the provided origin, scene, or version is invalid.\n",
      " |\n",
      " |  get_base_url(self, datasource: str) -> tuple[str, ...]\n",
      " |      Get the base URL for the GridSat-GOES/CONUS dataset's products.\n",
      " |\n",
      " |      This method returns the base URL for the GridSat-GOES/CONUS\n",
      " |      imagery dataset's products. The base URL is used to construct\n",
      " |      the full URL to the dataset's product files.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      datasource : str\n",
      " |          The datasource identifier. This parameter is used to\n",
      " |          determine the base URL for the dataset's products. The only\n",
      " |          available datasource is 'NOAA'. No datasource is supported\n",
      " |          yet.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      tuple[str, ...]\n",
      " |          The base URL for the GridSat-GOES/CONUS imagery dataset's\n",
      " |          products based on the requested datasource identifier.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          If the provided datasource is not supported or unavailable.\n",
      " |\n",
      " |  next_time(self, current_time: datetime.datetime) -> datetime.datetime\n",
      " |      Get the next time interval.\n",
      " |\n",
      " |      Get the next time interval based on the current time interval.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      current_time : datetime\n",
      " |          The current time interval.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      datetime\n",
      " |          The next time interval.\n",
      " |\n",
      " |  normalize_times(\n",
      " |      self,\n",
      " |      datetime_ini: datetime.datetime,\n",
      " |      datetime_fin: datetime.datetime\n",
      " |  ) -> tuple[datetime.datetime, datetime.datetime]\n",
      " |      Normalise the initial and final datetimes.\n",
      " |\n",
      " |      Normalise the initial and final datetimes to the nearest\n",
      " |      time interval based on the dataset. The initial datetime is\n",
      " |      normalised to the start of the time interval and the final\n",
      " |      datetime is normalised to the end of the time interval.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      datetime_ini : datetime\n",
      " |          The initial datetime.\n",
      " |      datetime_fin : datetime\n",
      " |          The final datetime.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      tuple[datetime, datetime]\n",
      " |          A tuple containing the normalised initial and final\n",
      " |          datetimes.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |\n",
      " |  truncate_to_month(time: datetime.datetime) -> datetime.datetime\n",
      " |      Truncate the `datetime` to the current month.\n",
      " |\n",
      " |      The `datetime` is truncated to the beginning of the current\n",
      " |      month.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      time : datetime\n",
      " |          The `datetime` to be truncated to the current month.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      datetime\n",
      " |          The `datetime` truncated to the current month.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |\n",
      " |  AVAILABLE_DATASOURCES = {'HTTP': 'https://www.ncei.noaa.gov/data/grids...\n",
      " |\n",
      " |  AVAILABLE_ORIGINS = {'G08': 'goes08', 'G09': 'goes09', 'G10': 'goes10'...\n",
      " |\n",
      " |  AVAILABLE_SCENES = {'C': 'CONUS (Contiguous United States)', 'F': 'Ful...\n",
      " |\n",
      " |  SCENE_TO_NAME = {'C': 'CONUS', 'F': 'GOES'}\n",
      " |\n",
      " |  SUPPORTED_DATASOURCES = {'HTTP'}\n",
      " |\n",
      " |  SUPPORTED_VERSIONS = {'v01'}\n",
      " |\n",
      " |  __abstractmethods__ = frozenset()\n",
      " |\n",
      " |  __annotations__ = {'AVAILABLE_DATASOURCES': dict[str, str], 'AVAILABLE...\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from goesdl.gridsat.locator.GridSatProductLocator:\n",
      " |\n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |\n",
      " |  __replace__ = _replace(self, /, **changes) from dataclasses\n",
      " |\n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |\n",
      " |  __setattr__(self, name, value)\n",
      " |      Implement setattr(self, name, value).\n",
      " |\n",
      " |  get_date_format(self) -> str\n",
      " |      Return the date format specification for the product's filename.\n",
      " |\n",
      " |      Generates and returns the date format specification for\n",
      " |      the product's filename based on the GridSat dataset product\n",
      " |      filename's date and time format conventions. The date format\n",
      " |      specification string is used to parse the product's filename\n",
      " |      and extract the `datetime` information.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          The date format specification for the GridSat product's\n",
      " |          filename.\n",
      " |\n",
      " |  get_paths(\n",
      " |      self,\n",
      " |      datetime_ini: datetime.datetime,\n",
      " |      datetime_fin: datetime.datetime\n",
      " |  ) -> list[str]\n",
      " |      Generate a list of dataset directory paths.\n",
      " |\n",
      " |      This method generates a list of directory paths within the\n",
      " |      dataset based on the folder structure and naming conventions,\n",
      " |      temporal granularity, and the specified date range. Paths to the\n",
      " |      folders containing the initial and final dates are included in\n",
      " |      the list.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      datetime_ini : datetime\n",
      " |          The initial datetime for the desired data.\n",
      " |      datetime_fin : datetime\n",
      " |          The final datetime for the desired data.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      list[str]\n",
      " |          A list of strings representing the paths to dataset\n",
      " |          directories containing the product files for the\n",
      " |          specified date range.\n",
      " |\n",
      " |  get_prefix(self) -> str\n",
      " |      Return the prefix for the product's filename.\n",
      " |\n",
      " |      Generates and returns the prefix for the GridSat product's\n",
      " |      filename based on product-specific information like dataset\n",
      " |      and product's name, instrument and origin's identifier, etc.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          The prefix for the GridSat product's filename.\n",
      " |\n",
      " |  get_suffix(self) -> str\n",
      " |      Return the suffix for the product's filename.\n",
      " |\n",
      " |      Generates and returns the suffix for the product's filename\n",
      " |      based on product-specific information like product's version\n",
      " |      origin's identifier, and file suffix (extension).\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          The suffix for the GridSat product's filename.\n",
      " |\n",
      " |  get_timestamp_pattern(self) -> str\n",
      " |      Return the timestamp regex pattern for the product's filename.\n",
      " |\n",
      " |      Generates and returns the timestamp regular expression\n",
      " |      pattern for the product's filename based on the dataset\n",
      " |      product filename's date and time format conventions. The\n",
      " |      timestamp regex pattern is used to extract the substring\n",
      " |      containing the timestamp from the product's filename\n",
      " |      before extracting the `datetime` information.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          The timestamp regex pattern for the GridSat product's\n",
      " |          filename.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from goesdl.gridsat.locator.GridSatProductLocator:\n",
      " |\n",
      " |  __dataclass_fields__ = {'file_date_format': Field(name='file_date_form...\n",
      " |\n",
      " |  __dataclass_params__ = _DataclassParams(init=True,repr=True,eq=False,o...\n",
      " |\n",
      " |  __match_args__ = ('name', 'origins', 'versions', 'file_date_format', '...\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from goesdl.dataset.locator_gg.ProductLocatorGG:\n",
      " |\n",
      " |  get_datetime(self, filename: str) -> datetime.datetime\n",
      " |      Extract the `datetime` from the product's filename.\n",
      " |\n",
      " |      This method parses the given filename and convert it to the\n",
      " |      corresponding `datetime` object from the product's filename\n",
      " |      using the dataset's date and time format conventions.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      filename : str\n",
      " |          The filename from which to extract the `datetime`.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      datetime\n",
      " |          The `datetime` extracted from the filename.\n",
      " |\n",
      " |      Raises\n",
      " |      ------\n",
      " |      ValueError\n",
      " |          If the filename does not match the expected pattern.\n",
      " |\n",
      " |  get_filename_pattern(self) -> str\n",
      " |      Return a regular expression pattern for the product's filename.\n",
      " |\n",
      " |      Generates and returns a regular expression pattern for the\n",
      " |      product's filename based on the prefix, date pattern, and\n",
      " |      suffix created with dataset-specific product information.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          The regular expression pattern for the product's filename\n",
      " |\n",
      " |  match(self, filename: str) -> bool\n",
      " |      Verify if a provided filename matches the required format.\n",
      " |\n",
      " |      Checks if the provided filename matches the product's filename\n",
      " |      pattern for the dataset product.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      filename : str\n",
      " |          The filename to match against the pattern.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      bool\n",
      " |          True if the filename matches the pattern, False otherwise.\n",
      " |\n",
      " |  timestamp_to_datetime(self, timestamp: str) -> datetime.datetime\n",
      " |      Convert a timestamp string to a UTC `datetime` object.\n",
      " |\n",
      " |      Parses and converts the provided timestamp string to a\n",
      " |      `datetime` object.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      The timestamp string extracted from the product's filename are\n",
      " |      (or assumed to be) always in UTC timezone. Consumer of product\n",
      " |      utilities should be aware of this assumption. The user could\n",
      " |      convert the `datetime` object to the desired timezone if needed.\n",
      " |\n",
      " |      The framework raises `ValueError` if the timestamp does not\n",
      " |      match the expected format or if the format specification is\n",
      " |      ill-formed.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      timestamp : str\n",
      " |          The timestamp string to convert to a `datetime` object.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      datetime\n",
      " |          The converted `datetime` object in UTC timezone.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from goesdl.dataset.locator.ProductLocator:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import goesdl.gridsat\n",
    "\n",
    "filter = goesdl.gridsat.GridSatProductLocatorGC(scene=\"F\", origins=\"G12\", versions=\"v01\")\n",
    "\n",
    "print(filter)\n",
    "print(filter.get_base_url(\"HTTP\"))\n",
    "# filter.get_datetime(\"HTTP\")\n",
    "# filter.get_paths(\"HTTP\")\n",
    "filter.match(\"HTTP\")\n",
    "help(filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "14705bf3-10e0-44c2-8731-275264965884",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = goesdl.gridsat.GridSatProductLocatorB1(versions=\"v02r01\")\n",
    "\n",
    "\n",
    "# filter.get_base_url(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3766129d-f4c8-4d42-b64e-f9ff91bf5d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Pruebas de selección de idioma ===\n",
      "\n",
      "1. Con parámetro 'es':\n",
      "Idioma seleccionado por parámetro: es\n",
      "   Resultado: es\n",
      "\n",
      "2. Con parámetro 'en':\n",
      "Idioma seleccionado por parámetro: en\n",
      "   Resultado: en\n",
      "\n",
      "3. Con variable GOESDL_LANG='es':\n",
      "Idioma seleccionado por variable de entorno: es\n",
      "   Resultado: es\n",
      "\n",
      "4. Con parámetro inválido 'fr':\n",
      "   Excepción: El idioma 'fr' no es válido. Use 'en' para inglés o 'es' para español.\n",
      "\n",
      "=== Fin de pruebas ===\n",
      "Idioma detectado del sistema operativo: en\n",
      "Idioma detectado actualmente: en\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Spacewatch\\AppData\\Local\\Temp\\ipykernel_13264\\928364179.py:48: DeprecationWarning: 'locale.getdefaultlocale' is deprecated and slated for removal in Python 3.15. Use setlocale(), getencoding() and getlocale() instead.\n",
      "  sys_lang, _ = locale.getdefaultlocale()\n"
     ]
    }
   ],
   "source": [
    "import contextlib\n",
    "import locale\n",
    "import os\n",
    "import typing as tp\n",
    "\n",
    "LangType = tp.Literal[\"en\", \"es\"]\n",
    "\n",
    "SUPPORTED_LANG = set(tp.get_args(LangType))\n",
    "\n",
    "\n",
    "def _get_lang(lang_param: str | None) -> str:\n",
    "    \"\"\"\n",
    "    Determina el idioma para mostrar la ayuda según la precedencia\n",
    "    establecida.\n",
    "\n",
    "    Args:\n",
    "        lang_param: Parámetro 'lang' pasado a la función factoría\n",
    "\n",
    "    Returns:\n",
    "        'en' para inglés o 'es' para español\n",
    "\n",
    "    Raises:\n",
    "        ValueError: Si lang_param no es None y no es 'en' o 'es'\n",
    "    \"\"\"\n",
    "    # 1. Verificar el parámetro lang\n",
    "    if lang_param is not None:\n",
    "        if lang_param not in SUPPORTED_LANG:\n",
    "            raise ValueError(\n",
    "                f\"El idioma '{lang_param}' no es válido. \"\n",
    "                \"Use 'en' para inglés o 'es' para español.\"\n",
    "            )\n",
    "        print(f\"Idioma seleccionado por parámetro: {lang_param}\")\n",
    "        return lang_param\n",
    "\n",
    "    # 2. Verificar la variable de entorno GOESDL_LANG\n",
    "    if env_lang := os.environ.get(\"GOESDL_LANG\"):\n",
    "        env_lang = env_lang.strip().lower()\n",
    "        if env_lang in SUPPORTED_LANG:\n",
    "            print(f\"Idioma seleccionado por variable de entorno: {env_lang}\")\n",
    "            return env_lang\n",
    "\n",
    "        # Si la variable existe pero tiene un valor no válido,\n",
    "        # ¿continuamos con el siguiente método o notificamos de la configuración incorrecta?\n",
    "\n",
    "    # 3. Intentar detectar el idioma del sistema operativo\n",
    "\n",
    "    with contextlib.suppress(Exception):\n",
    "        sys_lang, _ = locale.getdefaultlocale()\n",
    "        if sys_lang:\n",
    "            lang_code = sys_lang.split(\"_\")[0].lower()\n",
    "            if lang_code in SUPPORTED_LANG:\n",
    "                print(f\"Idioma detectado del sistema operativo: {lang_code}\")\n",
    "                return lang_code\n",
    "\n",
    "    # 4. Por defecto: inglés\n",
    "    return \"en\"\n",
    "\n",
    "\n",
    "# Función de prueba para verificar el comportamiento\n",
    "def test_lang_selection() -> None:\n",
    "    \"\"\"Función para probar la selección de idioma\"\"\"\n",
    "    print(\"=== Pruebas de selección de idioma ===\")\n",
    "\n",
    "    # Guardar estado original de variables de entorno\n",
    "    original_env = os.environ.get(\"GOESDL_LANG\")\n",
    "\n",
    "    # Test 1: Parámetro explícito\n",
    "    print(\"\\n1. Con parámetro 'es':\")\n",
    "    print(f\"   Resultado: {_get_lang('es')}\")\n",
    "\n",
    "    # Test 2: Parámetro 'en'\n",
    "    print(\"\\n2. Con parámetro 'en':\")\n",
    "    print(f\"   Resultado: {_get_lang('en')}\")\n",
    "\n",
    "    # Test 3: Variable de entorno\n",
    "    print(\"\\n3. Con variable GOESDL_LANG='es':\")\n",
    "    os.environ[\"GOESDL_LANG\"] = \"es\"\n",
    "    print(f\"   Resultado: {_get_lang(None)}\")\n",
    "\n",
    "    # Test 4: Parámetro inválido\n",
    "    print(\"\\n4. Con parámetro inválido 'fr':\")\n",
    "    try:\n",
    "        _get_lang(\"fr\")\n",
    "    except ValueError as e:\n",
    "        print(f\"   Excepción: {e}\")\n",
    "\n",
    "    # Restaurar variable de entorno\n",
    "    if original_env:\n",
    "        os.environ[\"GOESDL_LANG\"] = original_env\n",
    "    else:\n",
    "        del os.environ[\"GOESDL_LANG\"]\n",
    "\n",
    "    print(\"\\n=== Fin de pruebas ===\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Ejecutar pruebas\n",
    "    test_lang_selection()\n",
    "\n",
    "    # Mostrar idioma detectado actualmente\n",
    "    print(f\"Idioma detectado actualmente: {_get_lang(None)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb611850-1dff-44e6-9757-aadd88eb98f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('English_United Kingdom', 'utf8')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import locale\n",
    "\n",
    "locale.getlocale() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6c66c38d-76bc-4ff4-aa7d-5757d64f9f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'English_United Kingdom'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " locale.normalize(locale.getlocale()[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bcb93681-d888-48bd-ae82-da4926f672fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Spacewatch\\AppData\\Local\\Temp\\ipykernel_8744\\793819832.py:1: DeprecationWarning: 'locale.getdefaultlocale' is deprecated and slated for removal in Python 3.15. Use setlocale(), getencoding() and getlocale() instead.\n",
      "  locale.getdefaultlocale()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('en_GB', 'cp65001')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locale.getdefaultlocale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2847a286-bd26-4623-a48a-afab9021c2ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
