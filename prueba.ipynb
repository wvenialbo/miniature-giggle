{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YuZaEDJ6YmF"
      },
      "source": [
        "# Pruebas de la librería del TFG\n",
        "Este cuaderno contiene pruebas experimentales para la librería desarrollada en\n",
        "el Trabajo de Fin de Grado (TFG). Las pruebas están diseñadas para explorar\n",
        "nuevas características de la librería."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC0VVKpp6kz1"
      },
      "source": [
        "## Instalación de un copia desde el repositorio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLg5G-dCehpq"
      },
      "outputs": [],
      "source": [
        "!pip install -q git+https://github.com/wvenialbo/miniature-giggle.git@main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYBgme4a5Uyb"
      },
      "source": [
        "### Importación y verificación de la librería"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIckIu1R6Ida"
      },
      "outputs": [],
      "source": [
        "import tfg.storage\n",
        "import tfg.utils\n",
        "\n",
        "print(tfg.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83fwv3Po64GS"
      },
      "source": [
        "## Utilidad para descarga con streaming y reporte de progreso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74HS4xzW5Lw5"
      },
      "outputs": [],
      "source": [
        "import pathlib as pl\n",
        "from tqdm.auto import tqdm\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "def smart_download(ds, remote_uris: list[str], local_dest: str | pl.Path, max_workers: int = 4):\n",
        "    \"\"\"\n",
        "    Descarga archivos usando streaming.\n",
        "    \"\"\"\n",
        "    local_root = pl.Path(local_dest)\n",
        "\n",
        "    # Ejecución\n",
        "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        # Barra de progreso global (por archivos)\n",
        "        with tqdm(total=len(remote_uris), desc=\"Progreso Global\", unit=\"file\", position=0, leave=True) as main_pbar:\n",
        "            # Asignamos una posición a cada hilo para que las barras de tqdm se apilen\n",
        "            futures = [\n",
        "                executor.submit(_download_one, ds, local_root, uri, i % max_workers + 1)\n",
        "                for i, uri in enumerate(remote_uris)\n",
        "            ]\n",
        "            for future in as_completed(futures):\n",
        "                main_pbar.update(1)\n",
        "\n",
        "def _download_one(ds, local_root, uri: str, position: int):\n",
        "    # 1. Intentar obtener el tamaño para la barra de progreso\n",
        "    total_size = ds.get_size(uri=uri)\n",
        "\n",
        "    # 2. Preparar ruta local\n",
        "    # (Uso de lstrip para asegurar que sea relativa al root local)\n",
        "    relative_path = uri.split(ds.mountpoint)[-1].lstrip(\"/\")\n",
        "    target_path = local_root / relative_path\n",
        "    target_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # 3. Descarga con streaming\n",
        "    with tqdm(\n",
        "        total=total_size,\n",
        "        unit='B',\n",
        "        unit_scale=True,\n",
        "        desc=uri.split('/')[-1],\n",
        "        leave=False, # La barra desaparece al terminar para no saturar\n",
        "        position=position # Evita que las barras se solapen en multihilo\n",
        "    ) as pbar:\n",
        "        with open(target_path, \"wb\") as f:\n",
        "            for chunk in ds.stream(uri=uri):\n",
        "                f.write(chunk)\n",
        "                pbar.update(len(chunk))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_OQDGAf6wr4"
      },
      "source": [
        "## Mock de un Datasource con streaming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbZuXpHz5IPD"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import time\n",
        "import typing as tp\n",
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class MockResponse:\n",
        "    headers: dict\n",
        "    def raise_for_status(self): pass\n",
        "\n",
        "class MockMapper:\n",
        "\n",
        "    def to_native(self, uri: str) -> str:\n",
        "        return uri\n",
        "\n",
        "class BackendMock:\n",
        "    def __init__(self):\n",
        "        # Simulamos que tenemos un archivo de 50MB\n",
        "        self.file_size = 50 * 1024 * 1024\n",
        "        self.chunk_count = 50 # Lo dividiremos en 50 partes de 1MB\n",
        "\n",
        "    def size(self, *, uri: str) -> int:\n",
        "        return self.file_size\n",
        "\n",
        "    def read_chunk(self, *, uri: str, chunk_size: int = 1024 * 1024) -> tp.Iterable[bytes]:\n",
        "        for _ in range(self.chunk_count):\n",
        "            latencia = random.uniform(0.01, 0.15)\n",
        "            time.sleep(latencia)  # Simulamos latencia de red\n",
        "            yield b\"0\" * chunk_size # Enviamos un MB de \"datos\" dummy\n",
        "\n",
        "# Mock simple del Datasource para que funcione con smart_download\n",
        "class DatasourceMock:\n",
        "    def __init__(self):\n",
        "        self.backend = BackendMock()\n",
        "        self.mapper = MockMapper()\n",
        "        self.mountpoint = \"/ncei_data\"\n",
        "\n",
        "    def get_size(self, uri: str) -> int:\n",
        "        return self.backend.size(uri=uri)\n",
        "\n",
        "    def stream(self, uri: str) -> tp.Iterable[bytes]:\n",
        "        return self.backend.read_chunk(uri=uri)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ONFRCs26__a"
      },
      "source": [
        "## Caso de prueba con Mock"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2K32Lgr5OZw"
      },
      "outputs": [],
      "source": [
        "# 1. Instanciar el mock\n",
        "ds_mock = DatasourceMock()\n",
        "\n",
        "# 2. Definir archivos ficticios para descargar\n",
        "archivos_ficticios = [\n",
        "    \"/ncei_data/sensor_v1_2024.nc\",\n",
        "    \"/ncei_data/sensor_v2_2024.nc\",\n",
        "    \"/ncei_data/sensor_v3_2024.nc\",\n",
        "    \"/ncei_data/sensor_v4_2024.nc\",\n",
        "    \"/ncei_data/sensor_v5_2024.nc\",\n",
        "    \"/ncei_data/metadata_global.nc\",\n",
        "]\n",
        "\n",
        "# 3. Ejecutar la descarga inteligente\n",
        "print(\"Iniciando prueba de descarga concurrente con streaming...\")\n",
        "smart_download(\n",
        "    ds=ds_mock,\n",
        "    remote_uris=archivos_ficticios,\n",
        "    local_dest=\"./test_mock_download\",\n",
        "    max_workers=3\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mT-NxmL7FJe"
      },
      "source": [
        "## Casos de prueba con datasources reales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "es-T9gZmRpcl"
      },
      "source": [
        "### Servidor NCEI Archive - NOAA (HTTP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqWezzyx7LAy"
      },
      "outputs": [],
      "source": [
        "nc = tfg.storage.use_ncei_archive(dataset_path=\"gridsat-goes/access/goes\", cache_file=\"ncei.json\", expire_after=100.0)\n",
        "ls = tfg.storage.use_local_drive(root_path=\".\")\n",
        "\n",
        "content = nc.list(prefix=\"/2007/08/\")\n",
        "print(f\"Total de archivos: {len(content)}\")\n",
        "\n",
        "print(\"Iniciando prueba de descarga concurrente con streaming...\")\n",
        "smart_download(\n",
        "    ds=nc,\n",
        "    remote_uris=content[:2*3],\n",
        "    local_dest=\"./test_ncei_download\",\n",
        "    max_workers=3,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-WJW_V42iQa"
      },
      "source": [
        "### Amazon Web Services - NOAA (S3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W7AsthILelVz"
      },
      "outputs": [],
      "source": [
        "ds = tfg.storage.use_aws_cloud(bucket=\"noaa-goes16\", cache_file=\"aws.json\", expire_after=100.0)\n",
        "ls = tfg.storage.use_local_drive(root_path=\".\")\n",
        "\n",
        "content = ds.list(prefix=\"/ABI-L2-CMIPF/2020/319/20\")\n",
        "print(f\"Total de archivos: {len(content)}\")\n",
        "\n",
        "print(\"Iniciando prueba de descarga concurrente con streaming...\")\n",
        "smart_download(\n",
        "    ds=ds,\n",
        "    remote_uris=content[:2*3],\n",
        "    local_dest=\"./test_aws_download\",\n",
        "    max_workers=3,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hpy1EBgohRro"
      },
      "source": [
        "### Google Cloud Storage - NOAA (GCS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfHbK1ofEU9A"
      },
      "outputs": [],
      "source": [
        "gc = tfg.storage.use_gcs_cloud(bucket=\"gcp-public-data-goes-16\", cache_file=\"gcs.json\", expire_after=100.0)\n",
        "ls = tfg.storage.use_local_drive(root_path=\".\")\n",
        "\n",
        "content = ds.list(prefix=\"/ABI-L2-CMIPF/2020/319/20\")\n",
        "print(f\"Total de archivos: {len(content)}\")\n",
        "\n",
        "print(\"Iniciando prueba de descarga concurrente con streaming...\")\n",
        "smart_download(\n",
        "    ds=ds,\n",
        "    remote_uris=content[:2*3],\n",
        "    local_dest=\"./test_gcs_download\",\n",
        "    max_workers=3,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0J6zQKlM8Rzd"
      },
      "source": [
        "### Guardar archivo en el sistema local de archivos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naJf9OXA8ZAv"
      },
      "outputs": [],
      "source": [
        "data = ds.load(uri=content[0])\n",
        "ls.save(uri=content[0], data=data)\n",
        "print(type(data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tz4OcmSa7_-t"
      },
      "source": [
        "### Guardar archivo en el Drive (Montado en Google Colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70Li2Piue-lZ"
      },
      "outputs": [],
      "source": [
        "if tfg.utils.running_on_colab():\n",
        "    data = ds.load(uri=content[1])\n",
        "    cd = tfg.storage.use_colab_drive()\n",
        "    cd.save(uri=content[1], data=data)\n",
        "    print(type(data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJTxhVIStIpb"
      },
      "source": [
        "### Guardar archivo en el Drive (Usando Google Drive API)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CePcM4AUpfdL"
      },
      "outputs": [],
      "source": [
        "data = ds.load(uri=content[2])\n",
        "gd = tfg.storage.use_google_drive()\n",
        "gd.save(uri=content[2], data=data)\n",
        "print(type(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mrx5DgyqfB0g"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
